{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIPS Code + Shipment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Set default option\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "shipment = pd.read_parquet(\"../../Data/processed/shipment_eda.parquet\")\n",
    "fips_codes = pd.read_csv(\"../../Data/raw/county_fips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge operation directly since the columns are already in all caps\n",
    "shipment_fips = pd.merge(\n",
    "    shipment,\n",
    "    fips_codes[[\"BUYER_COUNTY\", \"BUYER_STATE\", \"countyfips\"]],\n",
    "    on=[\"BUYER_COUNTY\", \"BUYER_STATE\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BUYER_STATE BUYER_COUNTY  YEAR           MME countyfips\n",
      "41098          WI  FOND DU LAC  2016  2.347673e+07      55039\n",
      "15812          MA    HAMPSHIRE  2011  7.414830e+07      25015\n",
      "36627          TX         LYNN  2013  3.577728e+05      48305\n",
      "20517          MS      CALHOUN  2014  2.801195e+06      28013\n",
      "13820          KY       HARLAN  2011  1.971263e+07      21095\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values with a placeholder (0) before converting to integers\n",
    "shipment_fips[\"countyfips\"] = (\n",
    "    shipment_fips[\"countyfips\"].fillna(0).astype(int).astype(str).str.zfill(5)\n",
    ")\n",
    "\n",
    "# Replace the placeholder '00000' back to NaN\n",
    "shipment_fips[\"countyfips\"] = shipment_fips[\"countyfips\"].replace(\"00000\", np.nan)\n",
    "\n",
    "# Check the first few rows of the adjusted dataset\n",
    "print(shipment_fips.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows where 'BUYER_STATE' is 'AR' from the shipment_fips DataFrame, Montgomery changed name. \n",
    "shipment_fips = shipment_fips[shipment_fips['BUYER_COUNTY'] != 'MONTGOMERY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BUYER_STATE              BUYER_COUNTY  NaN_count\n",
      "0          GU                      GUAM         14\n",
      "1          MP  NORTHERN MARIANA ISLANDS          9\n",
      "2          MP                    SAIPAN          5\n",
      "3          PR                  ADJUNTAS         14\n",
      "4          PR                    AGUADA         14\n"
     ]
    }
   ],
   "source": [
    "# Checking for NaNs\n",
    "nan_fips = shipment_fips[shipment_fips[\"countyfips\"].isna()]\n",
    "\n",
    "# Group by 'BUYER_STATE' and 'BUYER_COUNTY' and count the NaN values\n",
    "nan_counts = (\n",
    "    nan_fips.groupby([\"BUYER_STATE\", \"BUYER_COUNTY\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"NaN_count\")\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(nan_counts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged shipment mapped with Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "population = pd.read_parquet(\"../../Data/processed/population.parquet\")\n",
    "state_codes = pd.read_csv(\"../../Data/raw/us_states-ab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the population dataset with the state abbreviations dataset\n",
    "population_state_code = pd.merge(\n",
    "    population, state_codes, left_on=\"State\", right_on=\"state\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the columns we don't need\n",
    "population_state_code = population_state_code.drop(\n",
    "    columns=[\"state\", \"abbrev\", \"State_Code\"]\n",
    ")\n",
    "\n",
    "# Rename the 'code' column from the state_codes DataFrame to 'State_Code'\n",
    "population_state_code.rename(columns={\"code\": \"State_Code\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BUYER_STATE BUYER_COUNTY  YEAR           MME countyfips    State   County  \\\n",
      "0          AL      AUTAUGA  2006  1.710054e+07      01001  Alabama  AUTAUGA   \n",
      "1          AL      AUTAUGA  2007  1.915784e+07      01001  Alabama  AUTAUGA   \n",
      "\n",
      "  County_Code    Year  Population State_Code  \n",
      "0       01001  2006.0       51328         AL  \n",
      "1       01001  2007.0       52405         AL  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'year' column to nullable integer if it's in 'shipment_fips'\n",
    "shipment_fips[\"YEAR\"] = shipment_fips[\"YEAR\"].astype(\"Int64\")\n",
    "\n",
    "# Ensure county names and state codes are in the same format\n",
    "shipment_fips[\"BUYER_COUNTY\"] = shipment_fips[\"BUYER_COUNTY\"].str.upper().str.strip()\n",
    "population_state_code[\"County\"] = (\n",
    "    population_state_code[\"County\"].str.upper().str.strip()\n",
    ")\n",
    "\n",
    "# Convert 'population' column to nullable integer if it's in 'population_state_code'\n",
    "population_state_code[\"Population\"] = population_state_code[\"Population\"].astype(\n",
    "    \"Int64\"\n",
    ")\n",
    "\n",
    "\n",
    "# Merge datasets on BUYER_STATE with State_Code, BUYER_COUNTY with County, and YEAR with Year\n",
    "shipment_with_population = pd.merge(\n",
    "    shipment_fips,\n",
    "    population_state_code,\n",
    "    left_on=[\"BUYER_STATE\", \"BUYER_COUNTY\", \"YEAR\"],\n",
    "    right_on=[\"State_Code\", \"County\", \"Year\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Check the first few rows \n",
    "print(shipment_with_population.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BUYER_STATE BUYER_COUNTY  YEAR           MME countyfips  Population\n",
      "7985           IA       MONONA  2015  2.536995e+06      19133        8865\n",
      "10540          IN         CLAY  2007  7.601827e+06      18021       26983\n",
      "6918           GA    WHITFIELD  2012  4.254906e+07      13313      102926\n",
      "41860          WV      LINCOLN  2008  7.543433e+06      54043       21881\n",
      "35796          TX       HARRIS  2009  1.014596e+09      48201     4034866\n",
      "12723          KS         RICE  2006  1.338461e+06      20159       10224\n",
      "17149          MI     MONTCALM  2018  1.670766e+07      26117        <NA>\n",
      "8187           IA       SHELBY  2007  1.645765e+06      19165       12496\n",
      "41494          WI     WAUKESHA  2006  1.110510e+08      55133      380799\n",
      "13992          KY      LETCHER  2015  1.674314e+07      21133       23043\n"
     ]
    }
   ],
   "source": [
    "# Drop redundant columns\n",
    "final_shipment_data = shipment_with_population.drop(\n",
    "    columns=[\"State\", \"County\", \"County_Code\", \"Year\", \"State_Code\"]\n",
    ")\n",
    "\n",
    "# Check the first few rows of the resulting DataFrame\n",
    "print(final_shipment_data.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR\n",
      "2006    83\n",
      "2007    83\n",
      "2008    83\n",
      "2009    83\n",
      "2013    83\n",
      "2010    82\n",
      "2011    82\n",
      "2012    82\n",
      "2014    82\n",
      "2015    81\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for years up to 2015\n",
    "shipment_data_up_to_2015 = final_shipment_data[final_shipment_data[\"YEAR\"] <= 2015]\n",
    "\n",
    "# Filter rows in the filtered DataFrame where Population is NaN or zero\n",
    "nan_or_zero_population_up_to_2015 = shipment_data_up_to_2015[\n",
    "    (shipment_data_up_to_2015[\"Population\"].isna())\n",
    "    | (shipment_data_up_to_2015[\"Population\"] == 0)\n",
    "]\n",
    "\n",
    "# Drop duplicates based on state, county, and year\n",
    "unique_nan_or_zero_population_up_to_2015 = (\n",
    "    nan_or_zero_population_up_to_2015.drop_duplicates(\n",
    "        subset=[\"BUYER_STATE\", \"BUYER_COUNTY\", \"YEAR\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print the number of unique rows by year\n",
    "print(unique_nan_or_zero_population_up_to_2015[\"YEAR\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select state and county columns\n",
    "unique_states_counties_with_nan_population = unique_nan_or_zero_population_up_to_2015[\n",
    "    [\"BUYER_STATE\", \"BUYER_COUNTY\"]\n",
    "]\n",
    "\n",
    "# Drop duplicates to get unique combinations\n",
    "unique_state_county_combinations = (\n",
    "    unique_states_counties_with_nan_population.drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GU' 'MP' 'PR' 'PW' 'VA' 'VI']\n"
     ]
    }
   ],
   "source": [
    "# Get unique state names for NaN population values\n",
    "unique_states_with_nan_population = unique_nan_or_zero_population_up_to_2015[\n",
    "    \"BUYER_STATE\"\n",
    "].unique()\n",
    "\n",
    "# Print the unique state names\n",
    "print(unique_states_with_nan_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BUYER_STATE BUYER_COUNTY  YEAR           MME countyfips  Population\n",
      "32347          SC    MCCORMICK  2012  1.364684e+06      45065        9926\n",
      "24046          ND        WELLS  2007  2.986549e+05      38103        4317\n",
      "27262          OH     CUYAHOGA  2007  2.843334e+08      39035     1301540\n",
      "13570          KY     FRANKLIN  2013  1.801955e+07      21073       49482\n",
      "30091          PA   CUMBERLAND  2014  1.084666e+08      42041      243400\n"
     ]
    }
   ],
   "source": [
    "# Extract the unique states with NaN or zero population\n",
    "states_to_drop = unique_nan_or_zero_population_up_to_2015['BUYER_STATE'].unique()\n",
    "\n",
    "# Filter out data from these states in the 'shipment_data_up_to_2015' DataFrame\n",
    "filtered_shipment_data = shipment_data_up_to_2015[~shipment_data_up_to_2015['BUYER_STATE'].isin(states_to_drop)]\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(filtered_shipment_data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUYER_STATE     False\n",
      "BUYER_COUNTY    False\n",
      "YEAR            False\n",
      "MME             False\n",
      "countyfips      False\n",
      "Population      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in all columns of the filtered dataset\n",
    "nan_columns_exist = filtered_shipment_data.isna().any()\n",
    "\n",
    "# Print the result\n",
    "print(nan_columns_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path and name for the parquet file\n",
    "file_path = '../../Data/processed/shipment_corrected.parquet'\n",
    "\n",
    "# Save the DataFrame to a parquet file\n",
    "filtered_shipment_data.to_parquet(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
